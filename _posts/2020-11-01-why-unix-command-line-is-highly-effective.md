---
layout: post
title: "なぜ Unix コマンドラインが高効率なのか"
description: ""
tags: 
---

こんなことはプログラマにとって常識であり、すでに語り尽くされているし、『UNIXという考え方』という書籍すら存在している。
しかしながら、先日に[ある問題](https://webkit.org/b/218375)を調査しバグレポートをしていて、改めてその便利さをしみじみと感じたので書きたくなった。
Unix コマンドラインが高効率である理由を考えると以下の要因が上げられる。

1. 抱負なコマンド郡により多くの作業が one-liner で解決する高効率
2. programmable
3. cross-platform (Windows, Mac, Linux で使える)
4. プログラマ同士の共通言語として使える

前述のある問題とはあるプログラムでローカルの web server に何度もアクセスしていると、低頻度で失敗するいうものだった。
そのときに調査に使った one-liner は以下のようなものだった。

~~~
seq 1000 | xargs -n 1 -P 30 curl --no-progress-meter http://localhost/ -o
yes http://localhost/ | head -1000 | ./my-programm > ouput.txt
grep XYZ ouput.txt | cat -n | grep ABC
~~~

まず curl コマンドを並列に30個起動してローカルの web server に 1000 回アクセスしその結果をファイルに保存した。
そのファイルを md5sum でチェックしてその web server は負荷をかけても問題がでないことを確認した。
xargs に便利な -P オプションがあるお陰で one-liner で済んだ。

次にその URL を1000行繰り返したテキストをプログラムに入力している。
わざわざテキストエディタで1000行のファイルを作成する必要はない。
プログラマ同士の共通言語として使えるため利用したコマンドラインをそのままバグレポートに記載している。
そうすることでわざわざ「テキストエディタで1000行のファイルを作成しました」などと説明する必要がない。

出力結果から XYZ を含む行を抜き出し、行番号をつけて、ABC を含む行を抜き出した。
これでどれくらいの頻度で失敗したかを確認することができた。

ただし問題もあって、コマンドやコマンドオプションに方言があるため気をつける必要がある。
上記のコマンドラインでも xargs -P や cat -n などは GNU 拡張である。
特に Mac でこの問題に頻繁に遭遇し、 cross-platform というのはやや誇張である。

今調べてみると curl にはそもそも --parallel と --parallel-max というオプションがあることに気がついた。
しかしながら重要なことは xargs ならどんなコマンドでも組み合わせることができるということである。

PowerShell は基本 Windows のみなので③と④を満たさない。
しかしながら、Windows 限定であれば同様の利用で便利である。

